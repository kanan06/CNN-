{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2bU35MTwu5vHQpOY1cto2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanan06/CNN-/blob/code/grp_6(lung_cancer_detection_using_AI)_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjUr32DO1AuQ"
      },
      "outputs": [],
      "source": [
        "####Importing dataset and libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import dicom\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import math\n",
        "\n",
        "##Data directory\n",
        "dataDirectory = 'Lung_Cancer/stage1/stage1/'\n",
        "lungPatients = os.listdir(dataDirectory)\n",
        "\n",
        "##Read labels csv \n",
        "labels = pd.read_csv('Lung_Cancer/stage1_labels/stage1_labels.csv', index_col=0)\n",
        "\n",
        "##Setting x*y size to 50\n",
        "size = 50\n",
        "\n",
        "## Setting z-dimension (number of slices to 20)\n",
        "NoSlices = 20"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###Data Preprocessing\n",
        "def chunks(l, n):\n",
        "    count = 0\n",
        "    for i in range(0, len(l), n):\n",
        "        if (count < NoSlices):\n",
        "            yield l[i:i + n]\n",
        "            count = count + 1\n",
        "\n",
        "\n",
        "def mean(l):\n",
        "    return sum(l) / len(l)\n",
        "\n",
        "\n",
        "def dataProcessing(patient, labels_df, size=50, noslices=20, visualize=False):\n",
        "    label = labels_df.get_value(patient, 'cancer')\n",
        "    path = dataDirectory + patient\n",
        "    slices = [dicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
        "    slices.sort(key=lambda x: int(x.ImagePositionPatient[2]))\n",
        "\n",
        "    new_slices = []\n",
        "    slices = [cv2.resize(np.array(each_slice.pixel_array), (size, size)) for each_slice in slices]\n",
        "\n",
        "    chunk_sizes = math.floor(len(slices) / noslices)\n",
        "    for slice_chunk in chunks(slices, chunk_sizes):\n",
        "        slice_chunk = list(map(mean, zip(*slice_chunk)))\n",
        "        new_slices.append(slice_chunk)\n",
        "\n",
        "    if label == 1:\n",
        "        label = np.array([0, 1])\n",
        "    elif label == 0:\n",
        "        label = np.array([1, 0])\n",
        "    return np.array(new_slices), label\n",
        "\n",
        "\n",
        "imageData = []\n",
        "for num, patient in enumerate(lungPatients):\n",
        "    if num % 100 == 0:\n",
        "        print('Saved -', num)\n",
        "    try:\n",
        "        img_data, label = dataProcessing(patient, labels, size=size, noslices=NoSlices)\n",
        "        imageData.append([img_data, label,patient])\n",
        "    except KeyError as e:\n",
        "        print('Data is unlabeled')\n",
        "\n",
        "        \n",
        "##Results are saved as numpy file\n",
        "np.save('imageDataNew-{}-{}-{}.npy'.format(size, size, NoSlices), imageData)"
      ],
      "metadata": {
        "id": "d_kL9OM41F8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Using tensorflow framework for Conv3D and importing libraries\n",
        "Using tensorflow framework for Conv3D and importing libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import tflearn\n",
        "from tflearn.layers.conv import conv_3d, max_pool_3d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\\\n",
        "Loading the numpy file and setting train and validation datasets\n",
        "imageData = np.load('imageDataNew-50-50-20.npy')\n",
        "trainingData = imageData[0:800]\n",
        "validationData = imageData[-200:-100]\n",
        "\n",
        "x = tf.placeholder('float')\n",
        "y = tf.placeholder('float')\n",
        "size = 50\n",
        "keep_rate = 0.8\n",
        "NoSlices = 20"
      ],
      "metadata": {
        "id": "Xza4PeQt1Lfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convolution3d(x, W):\n",
        "    return tf.nn.conv3d(x, W, strides=[1, 1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "\n",
        "def maxpooling3d(x):\n",
        "    return tf.nn.max_pool3d(x, ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1], padding='SAME')\n",
        "\n",
        "\n",
        "def cnn(x):\n",
        "    x = tf.reshape(x, shape=[-1, size, size, NoSlices, 1])\n",
        "    convolution1 = tf.nn.relu(\n",
        "        convolution3d(x, tf.Variable(tf.random_normal([3, 3, 3, 1, 32]))) + tf.Variable(tf.random_normal([32])))\n",
        "    convolution1 = maxpooling3d(convolution1)\n",
        "    convolution2 = tf.nn.relu(\n",
        "        convolution3d(convolution1, tf.Variable(tf.random_normal([3, 3, 3, 32, 64]))) + tf.Variable(\n",
        "            tf.random_normal([64])))\n",
        "    convolution2 = maxpooling3d(convolution2)\n",
        "    convolution3 = tf.nn.relu(\n",
        "        convolution3d(convolution2, tf.Variable(tf.random_normal([3, 3, 3, 64, 128]))) + tf.Variable(\n",
        "            tf.random_normal([128])))\n",
        "    convolution3 = maxpooling3d(convolution3)\n",
        "    convolution4 = tf.nn.relu(\n",
        "        convolution3d(convolution3, tf.Variable(tf.random_normal([3, 3, 3, 128, 256]))) + tf.Variable(\n",
        "            tf.random_normal([256])))\n",
        "    convolution4 = maxpooling3d(convolution4)\n",
        "    convolution5 = tf.nn.relu(\n",
        "        convolution3d(convolution4, tf.Variable(tf.random_normal([3, 3, 3, 256, 512]))) + tf.Variable(\n",
        "            tf.random_normal([512])))\n",
        "    convolution5 = maxpooling3d(convolution4)\n",
        "    fullyconnected = tf.reshape(convolution5, [-1, 1024])\n",
        "    fullyconnected = tf.nn.relu(\n",
        "        tf.matmul(fullyconnected, tf.Variable(tf.random_normal([1024, 1024]))) + tf.Variable(tf.random_normal([1024])))\n",
        "    fullyconnected = tf.nn.dropout(fullyconnected, keep_rate)\n",
        "    output = tf.matmul(fullyconnected, tf.Variable(tf.random_normal([1024, 2]))) + tf.Variable(tf.random_normal([2]))\n",
        "    return output\n",
        "\n",
        "\n",
        "def network(x):\n",
        "    prediction = cnn(x)\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\n",
        "    epochs = 10\n",
        "    with tf.Session() as session:\n",
        "        session.run(tf.global_variables_initializer())\n",
        "        for epoch in range(epochs):\n",
        "            epoch_loss = 0\n",
        "            for data in trainingData:\n",
        "                try:\n",
        "                    X = data[0]\n",
        "                    Y = data[1]\n",
        "                    _, c = session.run([optimizer, cost], feed_dict={x: X, y: Y})\n",
        "                    epoch_loss += c\n",
        "                except Exception as e:\n",
        "                    pass\n",
        "\n",
        "            correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
        "           # if tf.argmax(prediction, 1) == 0:\n",
        "            accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
        "            print('Epoch', epoch + 1, 'completed out of', epochs, 'loss:', epoch_loss)\n",
        "            # print('Correct:',correct.eval({x:[i[0] for i in validationData], y:[i[1] for i in validationData]}))\n",
        "            print('Accuracy:', accuracy.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]}))\n",
        "        print('Final Accuracy:', accuracy.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]}))\n",
        "        patients = []\n",
        "        actual = []\n",
        "        predicted = []\n",
        "\n",
        "        finalprediction = tf.argmax(prediction, 1)\n",
        "        actualprediction = tf.argmax(y, 1)\n",
        "        for i in range(len(validationData)):\n",
        "            patients.append(validationData[i][2])\n",
        "        for i in finalprediction.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]}):\n",
        "            if(i==1):\n",
        "                predicted.append(\"Cancer\")\n",
        "            else:\n",
        "                predicted.append(\"No Cancer\")\n",
        "        for i in actualprediction.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]}):\n",
        "            if(i==1):\n",
        "                actual.append(\"Cancer\")\n",
        "            else:\n",
        "                actual.append(\"No Cancer\")\n",
        "        for i in range(len(patients)):\n",
        "            print(\"Patient: \",patients[i])\n",
        "            print(\"Actual: \", actual[i])\n",
        "            print(\"Predcited: \", predicted[i])\n",
        "\n",
        "        from sklearn.metrics import confusion_matrix\n",
        "        y_actual = pd.Series(\n",
        "            (actualprediction.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]})),\n",
        "            name='Actual')\n",
        "        y_predicted = pd.Series(\n",
        "            (finalprediction.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]})),\n",
        "            name='Predicted')\n",
        "        df_confusion = pd.crosstab(y_actual, y_predicted)\n",
        "        print(df_confusion)\n",
        "\n",
        "        ## Function to plot confusion matrix\n",
        "        def plot_confusion_matrix(df_confusion, title='Confusion matrix', cmap=plt.cm.gray_r):\\\n",
        "            \n",
        "            plt.matshow(df_confusion, cmap=cmap)  # imshow  \n",
        "            # plt.title(title)\n",
        "            plt.colorbar()\n",
        "            tick_marks = np.arange(len(df_confusion.columns))\n",
        "            plt.xticks(tick_marks, df_confusion.columns, rotation=45)\n",
        "            plt.yticks(tick_marks, df_confusion.index)\n",
        "            # plt.tight_layout()\n",
        "            plt.ylabel(df_confusion.index.name)\n",
        "            plt.xlabel(df_confusion.columns.name)\n",
        "            plt.show()\n",
        "        plot_confusion_matrix(df_confusion)\n",
        "        # print(y_true,y_pred)\n",
        "        # print(confusion_matrix(y_true, y_pred))\n",
        "        # print(actualprediction.eval({x:[i[0] for i in validationData], y:[i[1] for i in validationData]}))\n",
        "        # print(finalprediction.eval({x:[i[0] for i in validationData], y:[i[1] for i in validationData]}))"
      ],
      "metadata": {
        "id": "9qfd299m1Pdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Loading the numpy file and setting train and validation datasets\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import dicom\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import math\n",
        "\n",
        "##Data directory\n",
        "dataDirectory = 'Lung_Cancer/stage1/stage1/'\n",
        "lungPatients = os.listdir(dataDirectory)\n",
        "\n",
        "##Read labels csv \n",
        "labels = pd.read_csv('Lung_Cancer/stage1_labels/stage1_labels.csv', index_col=0)\n",
        "\n",
        "##Setting x*y size to 50\n",
        "size = 50\n",
        "\n",
        "## Setting z-dimension (number of slices to 20)\n",
        "NoSlices"
      ],
      "metadata": {
        "id": "TT3rybfw1WXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Building 3D CNN model\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import tflearn\n",
        "from tflearn.layers.conv import conv_3d, max_pool_3d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "imageData = np.load('imageDataNew-50-50-20.npy')\n",
        "trainingData = imageData[0:800]\n",
        "testData = imageData[-1:]\n",
        "\n",
        "x = tf.placeholder('float')\n",
        "y = tf.placeholder('float')\n",
        "size = 50\n",
        "keep_rate = 0.8\n",
        "NoSlices = 20\n",
        "\n",
        "\n",
        "def convolution3d(x, W):\n",
        "    return tf.nn.conv3d(x, W, strides=[1, 1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "\n",
        "def maxpooling3d(x):\n",
        "    return tf.nn.max_pool3d(x, ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1], padding='SAME')\n",
        "\n",
        "\n",
        "def cnn(x):\n",
        "    x = tf.reshape(x, shape=[-1, size, size, NoSlices, 1])\n",
        "    convolution1 = tf.nn.relu(\n",
        "        convolution3d(x, tf.Variable(tf.random_normal([3, 3, 3, 1, 32]))) + tf.Variable(tf.random_normal([32])))\n",
        "    convolution1 = maxpooling3d(convolution1)\n",
        "    convolution2 = tf.nn.relu(\n",
        "        convolution3d(convolution1, tf.Variable(tf.random_normal([3, 3, 3, 32, 64]))) + tf.Variable(\n",
        "            tf.random_normal([64])))\n",
        "    convolution2 = maxpooling3d(convolution2)\n",
        "    convolution3 = tf.nn.relu(\n",
        "        convolution3d(convolution2, tf.Variable(tf.random_normal([3, 3, 3, 64, 128]))) + tf.Variable(\n",
        "            tf.random_normal([128])))\n",
        "    convolution3 = maxpooling3d(convolution3)\n",
        "    convolution4 = tf.nn.relu(\n",
        "        convolution3d(convolution3, tf.Variable(tf.random_normal([3, 3, 3, 128, 256]))) + tf.Variable(\n",
        "            tf.random_normal([256])))\n",
        "    convolution4 = maxpooling3d(convolution4)\n",
        "    convolution5 = tf.nn.relu(\n",
        "        convolution3d(convolution4, tf.Variable(tf.random_normal([3, 3, 3, 256, 512]))) + tf.Variable(\n",
        "            tf.random_normal([512])))\n",
        "    convolution5 = maxpooling3d(convolution4)\n",
        "    fullyconnected = tf.reshape(convolution5, [-1, 1024])\n",
        "    fullyconnected = tf.nn.relu(\n",
        "        tf.matmul(fullyconnected, tf.Variable(tf.random_normal([1024, 1024]))) + tf.Variable(tf.random_normal([1024])))\n",
        "    fullyconnected = tf.nn.dropout(fullyconnected, keep_rate)\n",
        "    output = tf.matmul(fullyconnected, tf.Variable(tf.random_normal([1024, 2]))) + tf.Variable(tf.random_normal([2]))\n",
        "    return output\n",
        "\n",
        "\n",
        "def network(x):\n",
        "    prediction = cnn(x)\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\n",
        "    epochs = 10\n",
        "    with tf.Session() as session:\n",
        "        session.run(tf.global_variables_initializer())\n",
        "        for epoch in range(epochs):\n",
        "            epoch_loss = 0\n",
        "            for data in trainingData:\n",
        "                try:\n",
        "                    X = data[0]\n",
        "                    Y = data[1]\n",
        "                    _, c = session.run([optimizer, cost], feed_dict={x: X, y: Y})\n",
        "                    epoch_loss += c\n",
        "                except Exception as e:\n",
        "                    pass\n",
        "\n",
        "        patients = []\n",
        "        actual = []\n",
        "        predicted = []\n",
        "\n",
        "        finalprediction = tf.argmax(prediction, 1)\n",
        "        actualprediction = tf.argmax(y, 1)\n",
        "        for i in range(len(testData)):\n",
        "            patients.append(testData[i][2])\n",
        "        for i in finalprediction.eval({x: [i[0] for i in testData], y: [i[1] for i in testData]}):\n",
        "            if(i==1):\n",
        "                predicted.append(\"Cancer\")\n",
        "            else:\n",
        "                predicted.append(\"No Cancer\")\n",
        "\n",
        "        for i in range(len(patients)):\n",
        "            print(\"Patient: \",patients[i])\n",
        "            print(\"Predcited: \", predicted[i])\n"
      ],
      "metadata": {
        "id": "d-ZVF69H1XMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Detecting whether a patient has cancer or not\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import tflearn\n",
        "from tflearn.layers.conv import conv_3d, max_pool_3d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "imageData = np.load('imageDataNew-50-50-20.npy')\n",
        "trainingData = imageData[0:800]\n",
        "testData = imageData[-1:]\n",
        "\n",
        "x = tf.placeholder('float')\n",
        "y = tf.placeholder('float')\n",
        "size = 50\n",
        "keep_rate = 0.8\n",
        "NoSlices = 20\n",
        "\n",
        "\n",
        "def convolution3d(x, W):\n",
        "    return tf.nn.conv3d(x, W, strides=[1, 1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "\n",
        "def maxpooling3d(x):\n",
        "    return tf.nn.max_pool3d(x, ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1], padding='SAME')\n",
        "\n",
        "\n",
        "def cnn(x):\n",
        "    x = tf.reshape(x, shape=[-1, size, size, NoSlices, 1])\n",
        "    convolution1 = tf.nn.relu(\n",
        "        convolution3d(x, tf.Variable(tf.random_normal([3, 3, 3, 1, 32]))) + tf.Variable(tf.random_normal([32])))\n",
        "    convolution1 = maxpooling3d(convolution1)\n",
        "    convolution2 = tf.nn.relu(\n",
        "        convolution3d(convolution1, tf.Variable(tf.random_normal([3, 3, 3, 32, 64]))) + tf.Variable(\n",
        "            tf.random_normal([64])))\n",
        "    convolution2 = maxpooling3d(convolution2)\n",
        "    convolution3 = tf.nn.relu(\n",
        "        convolution3d(convolution2, tf.Variable(tf.random_normal([3, 3, 3, 64, 128]))) + tf.Variable(\n",
        "            tf.random_normal([128])))\n",
        "    convolution3 = maxpooling3d(convolution3)\n",
        "    convolution4 = tf.nn.relu(\n",
        "        convolution3d(convolution3, tf.Variable(tf.random_normal([3, 3, 3, 128, 256]))) + tf.Variable(\n",
        "            tf.random_normal([256])))\n",
        "    convolution4 = maxpooling3d(convolution4)\n",
        "    convolution5 = tf.nn.relu(\n",
        "        convolution3d(convolution4, tf.Variable(tf.random_normal([3, 3, 3, 256, 512]))) + tf.Variable(\n",
        "            tf.random_normal([512])))\n",
        "    convolution5 = maxpooling3d(convolution4)\n",
        "    fullyconnected = tf.reshape(convolution5, [-1, 1024])\n",
        "    fullyconnected = tf.nn.relu(\n",
        "        tf.matmul(fullyconnected, tf.Variable(tf.random_normal([1024, 1024]))) + tf.Variable(tf.random_normal([1024])))\n",
        "    fullyconnected = tf.nn.dropout(fullyconnected, keep_rate)\n",
        "    output = tf.matmul(fullyconnected, tf.Variable(tf.random_normal([1024, 2]))) + tf.Variable(tf.random_normal([2]))\n",
        "    return output\n",
        "\n",
        "\n",
        "def network(x):\n",
        "    prediction = cnn(x)\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\n",
        "    epochs = 10\n",
        "    with tf.Session() as session:\n",
        "        session.run(tf.global_variables_initializer())\n",
        "        for epoch in range(epochs):\n",
        "            epoch_loss = 0\n",
        "            for data in trainingData:\n",
        "                try:\n",
        "                    X = data[0]\n",
        "                    Y = data[1]\n",
        "                    _, c = session.run([optimizer, cost], feed_dict={x: X, y: Y})\n",
        "                    epoch_loss += c\n",
        "                except Exception as e:\n",
        "                    pass\n",
        "\n",
        "        patients = []\n",
        "        actual = []\n",
        "        predicted = []\n",
        "\n",
        "        finalprediction = tf.argmax(prediction, 1)\n",
        "        actualprediction = tf.argmax(y, 1)\n",
        "        for i in range(len(testData)):\n",
        "            patients.append(testData[i][2])\n",
        "        for i in finalprediction.eval({x: [i[0] for i in testData], y: [i[1] for i in testData]}):\n",
        "            if(i==1):\n",
        "                predicted.append(\"Cancer\")\n",
        "            else:\n",
        "                predicted.append(\"No Cancer\")\n",
        "\n",
        "        for i in range(len(patients)):\n",
        "            print(\"Patient: \",patients[i])\n",
        "            print(\"Predcited: \", predicted[i])\n",
        "\n",
        "     \n",
        "network(x)"
      ],
      "metadata": {
        "id": "40uuV9Oy1oEO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}